{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3EcBpbzGMGX3jSdPgmvz1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reisdout/FederatedColab/blob/main/federated_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive  \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNTtfle5C1Xr",
        "outputId": "0affa34c-44ed-4462-fdbd-a90879e41620"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.base import RegressorMixin\n",
        "from tensorflow.python import training"
      ],
      "metadata": {
        "id": "05Xx_xP4S3Om"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ai-pool.com/d/how-to-get-the-weights-of-keras-model-\n",
        "\n",
        "Keras has implemented some functions for getting or setting weights for every layer. \n",
        "\n",
        "    layer.get_weights(): returns the weights of the layer as a list of Numpy arrays.\n",
        "    layer.set_weights(weights): sets the weights of the layer from a list of Numpy arrays.\n",
        "\n",
        "Using these functions you can write a piece of code to get all layers' weights\n",
        "\n",
        "for layer in model.layers:\n",
        "    weights = layer.get_weights() # list of numpy arrays\n",
        "\n",
        "Or you can get the weights right from the model\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "# ...\n",
        "weights = model.get_weights() # returs a numpy list of weights\n",
        "\n",
        "Keras model also has get_weights() and set_weights(weights) functions like every layer has.\n",
        "\n",
        "If you need more take a look at this keras doc.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "https://stackoverflow.com/questions/47183159/how-to-set-weights-in-keras-with-a-numpy-array\n",
        "\n",
        "The set_weights() method of keras accepts a list of numpy arrays, what you have passed to the method seems like a single array. The shape of this should be the same as the shape of the output of get_weights() on the same layer. Here's the code:\n",
        "```\n",
        "l=[]\n",
        "x=np.array() #weights\n",
        "y=np.array() #array of biases\n",
        "l.append(x)\n",
        "l.append(y)\n",
        "```\n",
        "\n",
        "loaded_model.layers[0].set_weights(l) #loaded_model.layer[0] being the layer\n"
      ],
      "metadata": {
        "id": "toe_0JZL3FTF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2L_CN_jZMB0R"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  \n",
        "class Server_FederatedOMS:\n",
        "  \n",
        "  In the central server, we decide to use only the highest\n",
        "  accuracy holder model as the central server updated model, send it to the local\n",
        "  clients after the computation.\n",
        "\n",
        "\n",
        "\n",
        "  def ReceiveModelsFromClients(self, parIdCliente):\n",
        "    print(\"Recebido Modelo do Cliente 1\")\n",
        "  def Consolidar(self):\n",
        "    print(\"Consolidado todos os modelos\")\n",
        "  def FeedBackConsolidatedModel(self):\n",
        "    print (\"Modelos enviados\")\n",
        "\n",
        "  clients = ['Cliente1', 'Cliente2']\n",
        "\n",
        "\n",
        "class Server_FederatedBMA():\n",
        "\n",
        "owever, in the BMA technique, the central server receives\n",
        "four models with model accuracy performances from the local servers or clients.\n",
        "In the central server, we sort the model using their performances. Then we\n",
        "decide to use the two best models or half of the models based on performances.\n",
        "Then BMA technique loops through each model’s hidden layers and neurons to do\n",
        "the sum of the weights and average them accordingly.\n",
        "\n",
        "  def ReceiveModelsFromClients(self)\n",
        "  def Consolidar(self)\n",
        "  def FeedBackConsolidatedModel(self)\n",
        "\n",
        "    clients[] = ['Cliente1', 'Cliente2']\n",
        "\n",
        "\n",
        "\n",
        "    def __init__(self, parCentralServer, parId):\n",
        "      self.id=parId\n",
        "      self.centralServer = parCentralServer\n",
        "      #self.centralServer.RegisterClient(self,self)\n",
        "\n",
        "\n",
        "'''\n",
        "class Client():\n",
        "\n",
        "\n",
        "\n",
        "    #resultadoTreinamento = np.eye(10)\n",
        "\n",
        "    def __init__(self,parId,parTraininPath, parTestPath, parPrevisionWindow):\n",
        "      self.id=parId\n",
        "      self.trainingPath=parTraininPath\n",
        "      self.testPath = parTestPath\n",
        "      self.T = parPrevisionWindow\n",
        "      #centralServer = Server_FederatedAMA()\n",
        "      #confusionMatrizModelClient = np.full((2,2), 1)\n",
        "      #confusionMatrizModelServer = np.full((2,2), 2)\n",
        "      self.currentConfusionMatriz =np.full((2,2), 0)\n",
        "      self.weightsClientModel = np.array([])\n",
        "      self.weightsServerModel = []\n",
        "      #self.base = pd.DataFrame()\n",
        "      #self.base_treinamento =  np.array([])\n",
        "      self.real_congestion_test = np.array([])\n",
        "      #self.test_vectors = []\n",
        "      #self.previsores = []\n",
        "      #self.real_congestion = []\n",
        "      #self.regressor = Sequential()\n",
        "      self.input_shape =0;\n",
        "      self.len_base_teste = 0;\n",
        "      #self.centralServer.RegisterClient(self,self)\n",
        "\n",
        "    def EvaluateServerModel(self):\n",
        "      print (\"Modelo do Servidor avaliado\")\n",
        "\n",
        "    def LoadTainingDataSet(self):\n",
        "      base = pd.read_csv(self.trainingPath)\n",
        "      base = base.dropna()\n",
        "      base_treinamento = base.iloc[:, [1,2,3,5]].values\n",
        "      previsores=[]\n",
        "      real_congestion = []\n",
        "      for i in range(self.T, base_treinamento.shape[0]): #base_treinamento.shape[0] número de linhas dos dados de treinamento\n",
        "        previsores.append(base_treinamento[i-self.T:i, 0:4])\n",
        "        real_congestion.append(base_treinamento[i, 3])#O resultado é do último cara\n",
        "      previsores, real_congestion = np.array(previsores), np.array(real_congestion)\n",
        "      self.input_shape = previsores.shape[1]\n",
        "      return previsores, real_congestion\n",
        "\n",
        "\n",
        "    def RefreshModel(self, parInitial=False): #Constroi na primeira vez e atualiza, a partir da avaliação do servidor cetral\n",
        "      #pensar melhor no critério\n",
        "      previsores,real_congestion = self.LoadTainingDataSet()\n",
        "      regressor = Sequential()\n",
        "      \n",
        "      if(parInitial):#tem que construir a rede do zero e treinar os pesos\n",
        "        regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (self.input_shape, 4)))# 4, pois são 4 previsores\n",
        "        regressor.add(Dropout(0.3)) #zerar 30% das entradas para evitar o overfiting\n",
        "        regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "        regssor.add(Dropout(0.3))\n",
        "        regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "        regressor.add(Dropout(0.3))\n",
        "        regressor.add(LSTM(units = 50))\n",
        "        regressor.add(Dropout(0.3))\n",
        "\n",
        "        '''\n",
        "        Segundo https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
        "        as saídas de cada unidade da LSTM e, portanto, a saída global é a dimenção do número de previsores, que, no nosso\n",
        "        caso, é 4. Daí esses 4 estão sendo levados em um softmax de tres neurônios, pois há tres categorias no final\"\n",
        "        ''' \n",
        "        regressor.add(Dense(units = 1, activation = 'sigmoid', name=\"client_\"+str(self.id)))\n",
        "        regressor.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics = ['mean_absolute_error'])\n",
        "        es = EarlyStopping(monitor = 'loss', min_delta = 1e-10, patience = 10, verbose = 1)\n",
        "        rlr = ReduceLROnPlateau(monitor = 'loss', factor = 0.2, patience = 5, verbose = 1)\n",
        "        mcp = ModelCheckpoint(filepath = 'pesos.h5', monitor = 'loss', \n",
        "                      save_best_only = True, verbose = 1)\n",
        "        regressor.fit(previsores, real_congestion, epochs = 100, batch_size = 32,\n",
        "                      callbacks = [es, rlr, mcp])\n",
        "        self.weightsClientModel = regressor.get_weights()\n",
        "      else:\n",
        "        if(self.ServerModelIsBetter()):\n",
        "          print(\"Pesos atualizados de acordo com o modelo do servidor\")\n",
        "        else:\n",
        "           print(\"Pesos Mantidos de acordo com o modelo do cliente\")\n",
        "\n",
        "    def GetMapedMatrix(self,parPrevisoes):\n",
        "      classe_teste2 = np.array([])\n",
        "      previsoes2 =  np.array([])\n",
        "\n",
        "      for i in range(0, self.len_base_teste):\n",
        "        if(self.real_congestion_test[i] < 0.3):\n",
        "          classe_teste2 = np.append(classe_teste2,0)\n",
        "        elif (self.real_congestion_test[i,0] >= 0.3 and self.real_congestion_test[i] < 0.75):\n",
        "          classe_teste2= np.append(classe_teste2,1)\n",
        "        else:\n",
        "          classe_teste2 = np.append(classe_teste2,2)\n",
        "\n",
        "      for i in range(0, len(parPrevisoes)):\n",
        "        if(parPrevisoes[i] < 0.3):\n",
        "          previsoes2= np.append(previsoes2,0)\n",
        "        elif (parPrevisoes[i] >= 0.3 and parPrevisoes[i] < 0.75):\n",
        "          previsoes2= np.append(previsoes2,1)\n",
        "        else:\n",
        "          previsoes2 = np.append(previsoes2,2)\n",
        "\n",
        "      return classe_teste2, previsoes2\n",
        "\n",
        "\n",
        "    def EvalueteServerModel(self, parServerModel):\n",
        "\n",
        "      test_vectors = self.LoadTestData()\n",
        "      previsoes = parServerModel.predict(test_vectors)\n",
        "      updated = False\n",
        "      '''\n",
        "      Observe que os previsores teste tem 90 quádruplas que conduzem ao resultado\n",
        "      do último estado, da quádrupla 90. Prontamente preparado para pevisões....\n",
        "      '''\n",
        "      classe_teste2,previsoes2 = self.GetMapedMatrix(previsoes)\n",
        "      matriz = confusion_matrix(classe_teste2,previsoes2)\n",
        "      currentSum = 0\n",
        "      newSum = 0\n",
        "      if(self.currentConfusionMatriz.ndim > 1): # as vezes a rede pode errar ao ponto de dar só uma categoria, daí cai no else...\n",
        "        for i in range (0, len(self.currentConfusionMatriz)):\n",
        "            currentSum = currentSum + self.currentConfusionMatriz[i][i]\n",
        "      else:\n",
        "        currentSum = self.currentConfusionMatriz[i]\n",
        "      if(matriz.ndim > 1):\n",
        "        for i in range (0, len(matriz)):\n",
        "          newSum = newSum + matriz[i][i]\n",
        "      else:\n",
        "        newSum = matriz[i]\n",
        "      if(newSum > currentSum):\n",
        "        self.currentConfusionMatriz = np.array(matriz)\n",
        "        self.regressor.set_weights(self.weightsServerModel)\n",
        "        updated = True\n",
        "      print (\"Modelo do Servidor avaliado\")\n",
        "      return updated \n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "    def LoadTestData(self):\n",
        "      base = pd.read_csv(self.trainingPath)\n",
        "      base = base.dropna()\n",
        "      base_teste = pd.read_csv(self.testPath)\n",
        "      base_teste = base_teste.dropna()\n",
        "      self.real_congestion_test = base_teste.iloc[:, 5:6].values\n",
        "      frames = [self.base, self.base_teste]\n",
        "      base_completa = pd.concat(frames)\n",
        "      base_completa = base_completa.drop('#Ack', axis =1)\n",
        "      base_completa = base_completa.drop('cwnd (Bytes/1000)', axis =1)\n",
        "      base_completa = base_completa.drop('Network Situation', axis =1)\n",
        "      base_completa = base_completa.drop('AckArrival(ms)', axis =1)\n",
        "      base_completa = base_completa.drop('TSInsideAck(ms)', axis =1)\n",
        "      base_completa = base_completa.drop('RTTAck(ms)', axis =1)\n",
        "      entradas = base_completa[len(base_completa) - len(base_teste) - self.T:].values\n",
        "      #base_teste_features = base_teste.iloc[:, [1,2,3,6]].values\n",
        "      #print(\"#############\",len(base_teste))\n",
        "      self.len_base_teste = len(base_teste)\n",
        "      X_teste = []\n",
        "\n",
        "      for i in range(self.T, len(self.base_teste)+self.T): # para as duzentas previsoes, o mesmo tramanho do Teste.csv, ou seja 290-90\n",
        "        X_teste.append(entradas[i-self.T:i,0:4])\n",
        "\n",
        "\n",
        "      test_vectors = np.array(X_teste) # equivalente ao X_teste\n",
        "      return test_vectors\n",
        "    '''   \n",
        "    def RefreshConfusionClientMatrix(self):\n",
        "      #confrontar resultados\n",
        "      self.confusionMatrizModelClient = np.full((2,2),random.randint(0,9))\n",
        "\n",
        "    def RefreshConfusionServerMatrix(self):\n",
        "      #confrontar resultados\n",
        "      self.confusionMatrizModelServer = np.full((2,2),random.randint(0,9))\n",
        "    '''       \n",
        "    def ReceiveModelFromServer(self, parCandidateMatrix):\n",
        "      print(\"Cliente \", self.id, \" Recebido Modelo do Servidor\")\n",
        "      self.weightsServerModel.clear()\n",
        "      for e in parCandidateMatrix :\n",
        "        self.weightsServerModel.append(e)\n",
        "      \n",
        "    def SendModelToServer(self):\n",
        "      self.centralServ.ReceiveModelsFromClients(self.id)\n",
        "      print(\"Client\", self.id, \"Sending Model To Server\")\n",
        "    '''\n",
        "    def TreinarModelo(self):\n",
        "      print(\"Cliente \", self.id, \"treinando Modelo\")\n",
        "      time.sleep(random.randint(0,9))\n",
        "      self.RefreshConfusionClientMatrix()\n",
        "\n",
        "    '''\n",
        "    def GetPrevision(self): #evalueta indica que é uma avaliação do modelo recebido como parametro, no caso do servidor\n",
        "      test_vectors = self.LoadTestData()\n",
        "      previsoes = self.regressor.predict(test_vectors)\n",
        "      #previsoes = parNeuralModel.predict(self.test_vectors)\n",
        "     \n",
        "      '''\n",
        "      Observe que os previsores teste tem 90 quádruplas que conduzem ao resultado\n",
        "      do último estado, da quádrupla 90. Prontamente preparado para pevisões....\n",
        "      '''\n",
        "      #classe_teste2 = np.array([])\n",
        "      #previsoes2 =  np.array([])\n",
        "      classe_teste2,previsoes2 = self.GetMapedMatrix(previsoes)\n",
        "      '''\n",
        "      for i in range(0, len(self.base_teste)):\n",
        "        if(self.real_congestion_test[i] < 0.3):\n",
        "          classe_teste2 = np.append(classe_teste2,0)\n",
        "        elif (self.real_congestion_test[i,0] >= 0.3 and self.real_congestion_test[i] < 0.75):\n",
        "          classe_teste2= np.append(classe_teste2,1)\n",
        "        else:\n",
        "          classe_teste2 = np.append(classe_teste2,2)\n",
        "\n",
        "      for i in range(0, len(previsoes)):\n",
        "        if(previsoes[i] < 0.3):\n",
        "          previsoes2= np.append(previsoes2,0)\n",
        "        elif (previsoes[i] >= 0.3 and previsoes[i] < 0.75):\n",
        "          previsoes2= np.append(previsoes2,1)\n",
        "        else:\n",
        "          previsoes2 = np.append(previsoes2,2)\n",
        "      '''\n",
        "      self.currentConfusionMatriz = confusion_matrix(classe_teste2,previsoes2)\n",
        "      return self.currentConfusionMatriz # Com a configuração corrente, essa é a matriz....\n",
        "        \n",
        "\n",
        "    def ServerModelIsBetter(self):\n",
        "        regressorServer = Sequential()\n",
        "        regressorServer.add(LSTM(units = 100, return_sequences = True, input_shape = (self.input_shape, 4)))# 4, pois são 4 previsores\n",
        "        regressorServer.add(Dropout(0.3)) #zerar 30% das entradas para evitar o overfiting\n",
        "        regressorServer.add(LSTM(units = 50, return_sequences = True))\n",
        "        regressorServer.add(Dropout(0.3))\n",
        "        regressorServer.add(LSTM(units = 50, return_sequences = True))\n",
        "        regressorServer.add(Dropout(0.3))\n",
        "        regressorServer.add(LSTM(units = 50))\n",
        "        regressorServer.add(Dropout(0.3))\n",
        "\n",
        "        '''\n",
        "        Segundo https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
        "        as saídas de cada unidade da LSTM e, portanto, a saída global é a dimenção do número de previsores, que, no nosso\n",
        "        caso, é 4. Daí esses 4 estão sendo levados em um softmax de tres neurônios, pois há tres categorias no final\"\n",
        "        ''' \n",
        "        regressorServer.add(Dense(units = 1, activation = 'sigmoid',name=\"client_eval_\"+str(self.id)))\n",
        "        regressorServer.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics = ['mean_absolute_error'])\n",
        "        regressorServer.set_weights(self.weightsServerModel)\n",
        "        return self.EvalueteServerModel(regressorServer)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Server_FederatedAMA():\n",
        "  '''\n",
        "  During the aggregation,\n",
        "  we first sum and average the neuron weights of each model. Then we store the\n",
        "  average value in the designated global model position. In the neural network\n",
        "  model, the same process is calculated for every neuron. After completing Al-\n",
        "  gorithm 2, the central server aggregated model is sent to all the clients for the\n",
        "  next learning phase\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    self.clients = []\n",
        "    self.ReceivedModel = [False,False,False]\n",
        "    self.consolidateWeightMatrix = []\n",
        "\n",
        "  def PrintRegistredClients(self):\n",
        "    print(\"Registred Clients\")\n",
        "    for x in self.clients:\n",
        "      print(\"Client \", x.id)\n",
        "  \n",
        "  def RegisterClient(self, parCliente):\n",
        "    self.clients.append(parCliente)\n",
        "    #print(\"Cliente \", parCliente.id, \" Regitrado com sucesso\")\n",
        "\n",
        "  '''\n",
        "  def ReceiveModelsFromClient(self, parId):\n",
        "   print(\"Recebido Modelos dos Cliente \", parId)    \n",
        "   self.ConsolideModels()\n",
        "\n",
        "  '''  \n",
        "    \n",
        "\n",
        "  def ConsolidateModels(self):\n",
        "\n",
        "    '''\n",
        "      #########################################################################################################################################\n",
        "      listaBase = [[\"amarelo\",\"verde\",\"preto\"], [\"azul\",\"abóbora\",\"marrom\"], [\"uva\",\"laranja\",\"branco\"]]\n",
        "      arrays_in_Layer=[]\n",
        "      lstTemp = []\n",
        "      lst_arrays_in_Layer = []\n",
        "      for layer in listaBase:\n",
        "          for arr in layer:\n",
        "              lstTemp.append(arr)\n",
        "          arrays_in_Layer = [i for i in lstTemp]\n",
        "          lst_arrays_in_Layer.append(arrays_in_Layer)\n",
        "          lstTemp.clear()\n",
        "      print (lst_arrays_in_Layer)\n",
        "      \n",
        "      \n",
        "      #uma inspiraçao\n",
        "      l=[]\n",
        "      x=np.array() #weights\n",
        "      y=np.array() #array of biases\n",
        "      l.append(x)\n",
        "      l.append(y)\n",
        "      loaded_model.layers[0].set_weights(l) #loaded_model.layer[0] being the layer\n",
        "  \n",
        "    '''\n",
        "    #client_layers = []\n",
        "\n",
        "    numberClients = len(self.clients)\n",
        "    #lstTemp = []\n",
        "    #arrays_in_Layer=[]\n",
        "    #lst_arrays_in_Layer = []\n",
        "    #lst_consolidated_arrays_in_layer = [] #as camadas, composta por arraysconsolidados\n",
        "    consolidated_arrays_in_layer = [] #arrays da camada\n",
        "    #consolidated_array = None\n",
        "    consolidated_model = []\n",
        "    clients_weighted_models = []\n",
        "    '''\n",
        "    #Cada weightsClientModel é uma lista de numpyarrays crua \"flatem\", isto é\n",
        "    se um modelo tem, por exemplo, 3 camadas e cada uma com dois arrays, o \n",
        "    weightsClientModel será uma lista de 6 numpy´s, com os dois primeiros vetores da \n",
        "    primeira camada no início, seguidos dos dois da segunta e, depois, os dois da terceira.\n",
        "    Nada de listas. É uma Listona de numpys\n",
        "    '''\n",
        "    for client in self.clients:\n",
        "        #print(client.weightsClientModel)\n",
        "        #input(\"pesos acima\")\n",
        "        clients_weighted_models.append(client.weightsClientModel)\n",
        "    \n",
        "    \n",
        "    #Criando a estrutura do Modelo\n",
        "    #for model in client_weighted_model:\n",
        "    '''\n",
        "    count_arrays=0\n",
        "    count_layers=0\n",
        "    for arr in clients_weighted_models[0]:\n",
        "       if(arr.shape[0]):\n",
        "          count_arrays+=1\n",
        "          consolidated_arrays_in_layer.append(np.full((2,2), 0))\n",
        "    input(f\"Quantidade de Arrays {count_arrays} do modelo\")\n",
        "        \n",
        "    #for i in range(0,len (clients_weighted_models)):\n",
        "    print(\"Shapes do modelo Consolidado\")\n",
        "    for j in range (0, len(consolidated_model)):\n",
        "        for k in range (0, len (consolidated_model[j])):\n",
        "            #print (f\"({i},j{j},k{k}\")\n",
        "            print(\"consolidated shape--> (\", consolidated_model[j][k].shape,\")\")\n",
        "            \n",
        "    input(\"final das shape\")\n",
        "    \n",
        "    ############################################\n",
        "    \n",
        "    ###############Verificando as Shapes\n",
        "    \n",
        "    for i in range(0,len (clients_weighted_models)-1):\n",
        "        print(\"Verificando as shapes\")\n",
        "        #input(\"mais uma shape\")\n",
        "        for j in range (0, len(clients_weighted_models[i])):\n",
        "            for k in range (0, len (clients_weighted_models[i][j])):\n",
        "                \n",
        "                if(clients_weighted_models[i][j][k].shape != clients_weighted_models[i+1][j][k].shape):\n",
        "                        print(\"shapes incompativeis\")\n",
        "                        #exit(1)\n",
        "                       \n",
        "    \n",
        "    print(\"camadas cliente 0:\", len(clients_weighted_models[0][0]))\n",
        "    \n",
        "    print(\"camadas modelo consolidado: \", len(consolidated_model[0]))\n",
        "    '''\n",
        "    \n",
        "    for i in range(0,len (clients_weighted_models)):\n",
        "       for j in range (0, len(clients_weighted_models[i])):\n",
        "            if(i==0):\n",
        "                consolidated_model.append(clients_weighted_models[i][j])#alocando a lista com os pesos do primeiro modelo.\n",
        "            else:\n",
        "                consolidated_model[j] = consolidated_model[j] + clients_weighted_models[i][j]\n",
        "            if (i == numberClients - 1):\n",
        "                consolidated_model[j] = consolidated_model[j]/numberClients\n",
        "                \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    for model in client_weighted_model:\n",
        "        count_client = count_client + 1    \n",
        "        for layer in model:\n",
        "            for arr in layer:\n",
        "                if(count_client==0):\n",
        "                    consolidated_array = arr\n",
        "                else:\n",
        "                    consolidated_array = consolidated_array + arr\n",
        "                if (count_client == numberClients - 1):\n",
        "                    consolidated_array = consolidated_array/numberClients\n",
        "                consolidated_arrays_in_layer.append(consolidated_array)\n",
        "            lst_consolidated_arrays_in_layer.append(consolidated_arrays_in_layer)\n",
        "    \n",
        "\n",
        "    #obtendo os numpy de cada layer\n",
        "    count_client=-1\n",
        "    for model in client_weighted_model:\n",
        "        count_client = count_client + 1    \n",
        "        for layer in model:\n",
        "            for arr in layer:\n",
        "                if(count_client==0):\n",
        "                    consolidated_array = arr\n",
        "                else:\n",
        "                    consolidated_array = consolidated_array + arr\n",
        "                if (count_client == numberClients - 1):\n",
        "                    consolidated_array = consolidated_array/numberClients\n",
        "                consolidated_arrays_in_layer.append(consolidated_array)\n",
        "            lst_consolidated_arrays_in_layer.append(consolidated_arrays_in_layer)\n",
        "            \n",
        "    self.consolidateWeightedMatrix = lst_consolidated_arrays_in_layer\n",
        "                \n",
        "              \n",
        "      arrays_in_Layer = [i for i in lstTemp]\n",
        "      lst_arrays_in_Layer.append(arrays_in_Layer)\n",
        "      lstTemp.clear()\n",
        "      \n",
        "    client_layers.append(lst_arrays_in_Layer)\n",
        "    \n",
        "    #consolidando os pesos\n",
        "    cout_client=-1\n",
        "    for client_layer in client_layers:\n",
        "      cont_client = count_client+1  \n",
        "      for array_list in client_layer:\n",
        "        for array in array_list:\n",
        "            if(count_client==0):\n",
        "                consolidated_array = array\n",
        "            else:\n",
        "                consolidated_array = consolidated_array + array\n",
        "                \n",
        "        consolidated_arrays_in_layer.append(consolidated_array)\n",
        "      \n",
        "    \n",
        "    for i in range (1, numberClients):\n",
        "      self.consolidateWeightedMatrix = self.consolidateWeightedMatrix + self.clients[i].weightsClientModel\n",
        "    self.consolidateWeightedMatrix = self.consolidateWeightedMatrix/numberClients\n",
        "    print(\"Models were consolidated\")\n",
        "    \n",
        "    '''\n",
        "    #self.consolidateWeightMatrix = consolidated_model # cuidado com isso!\n",
        "    self.consolidateWeightMatrix.clear()\n",
        "    for e in consolidated_model:\n",
        "        self.consolidateWeightMatrix.append(e)\n",
        "\n",
        "    \n",
        "    print(\"Amostra Peso Clientes:\")\n",
        "    for client in self.clients:\n",
        "      print(\"============================\")\n",
        "      print(client.weightsClientModel[0][0][0:4])\n",
        "    print(\"Amostra Peso Consolidado: \")\n",
        "    print(self.consolidateWeightMatrix[0][0][0:4])\n",
        "    \n",
        "\n",
        "  def FeedBackConsolidatedModel(self):\n",
        "    for x in self.clients:\n",
        "      x.ReceiveModelFromServer(self.consolidateWeightMatrix)\n",
        "    print(\"Feedbacks Enviados\")\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separando Lista"
      ],
      "metadata": {
        "id": "WM23KmU7_urd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "listaBase = [[\"amarelo\",\"verde\",\"preto\"], [\"azul\",\"abóbora\",\"marrom\"], [\"uva\",\"laranja\",\"branco\"]]\n",
        "arrays_in_Layer=[]\n",
        "lstTemp = []\n",
        "lst_arrays_in_Layer = []\n",
        "for layer in listaBase:\n",
        "  for arr in layer:\n",
        "    lstTemp.append(arr)\n",
        "  arrays_in_Layer = [i for i in lstTemp]\n",
        "  lst_arrays_in_Layer.append(arrays_in_Layer)\n",
        "  lstTemp.clear()\n",
        "print (lst_arrays_in_Layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RoXYDyj85uB",
        "outputId": "b339d904-b55e-4f35-b248-530e296e59ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['amarelo', 'verde', 'preto'], ['azul', 'abóbora', 'marrom'], ['uva', 'laranja', 'branco']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Server::ConsolidateModels----------------Server::FeedBackConsolidatedModel--------------Client::RefreshModel\n",
        "'''\n",
        "\n",
        "#numClients = 3; #Can be gotten from user\n",
        "\n",
        "#lstClients = [];\n",
        "\n",
        "objServe = Server_FederatedAMA()\n",
        "\n",
        "#for i in range (numClients):\n",
        "  #objClient = Client(objServe,i)\n",
        "  #lstClients.append(objClient)\n",
        "\n",
        "#for x in lstClients:\n",
        "  #print(\"Cliente \", x.id, \"Criado com Sucesso\");\n",
        "\n",
        "\n",
        "#for x in lstClients:\n",
        " #objServe.RegisterClient(x)\n",
        "\n",
        "#objServe.PrintRegistredClients()\n",
        "\n",
        "'''\n",
        "for i in range (0,10):\n",
        "  print(\"==================Rodada \",i\" ========================\")\n",
        "  for x in lstClients:\n",
        "    x.TreinarModelo\n",
        "  for x in lstClients:\n",
        "    x.SendModelToServer\n",
        "  objServe.ConsolidateModels\n",
        "  objServe.FeedBackConsolidatedModel()\n",
        "  for x in lstClients:\n",
        "    x.AtualizarModelo();\n",
        "'''\n",
        "\n",
        "objClient1 = Client(0,'/content/drive/MyDrive/Colab Notebooks/Exp_000002/training_client01_Fri Feb 24 10_09_37.csv',\n",
        "                               '/content/drive/MyDrive/Colab Notebooks/Exp_000002/test_Fri Feb 24 09_39_49.csv', 90);\n",
        "\n",
        "#objClient1.LoadTainingDataSet()\n",
        "objClient1.RefreshModel(parInitial=True)\n",
        "\n",
        "\n",
        "objClient2 = Client(1,'/content/drive/MyDrive/Colab Notebooks/Exp_000002/training_client02_Fri Feb 24 10_09_37.csv',\n",
        "                               '/content/drive/MyDrive/Colab Notebooks/Exp_000002/test_Fri Feb 24 09_39_49.csv', 90);\n",
        "\n",
        "#objClient2.LoadTainingDataSet()\n",
        "objClient2.RefreshModel(parInitial=True)\n",
        "\n",
        "\n",
        "\n",
        "objClient3 = Client(2,'/content/drive/MyDrive/Colab Notebooks/Exp_000002/training_client03_10_1_2_2to10_35_0_2_trainingFri Feb 24 10_09_37.csv',\n",
        "                               '/content/drive/MyDrive/Colab Notebooks/Exp_000002/test_Fri Feb 24 09_39_49.csv', 90);\n",
        "\n",
        "#objClient3.LoadTainingDataSet()\n",
        "objClient3.RefreshModel(parInitial=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "226DTudwM1mO",
        "outputId": "a8849ec7-b014-401e-a6dd-7bb7c2ec4980"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-cbf675eba7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#objClient1.LoadTainingDataSet()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mobjClient1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRefreshModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparInitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-4bc6a4231eff>\u001b[0m in \u001b[0;36mRefreshModel\u001b[0;34m(self, parInitial)\u001b[0m\n\u001b[1;32m    113\u001b[0m         mcp = ModelCheckpoint(filepath = 'pesos.h5', monitor = 'loss', \n\u001b[1;32m    114\u001b[0m                       save_best_only = True, verbose = 1)\n\u001b[0;32m--> 115\u001b[0;31m         self.regressor.fit(previsores, real_congestion, epochs = 100, batch_size = 32,\n\u001b[0m\u001b[1;32m    116\u001b[0m                       callbacks = [es, rlr, mcp])\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightsClientModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################Testando#################################\n",
        "\n",
        "#objClient1.LoadTestData()\n",
        "objClient1.GetPrevision()\n",
        "print (objClient1.currentConfusionMatriz)\n",
        "\n",
        "#objClient2.LoadTestData()\n",
        "objClient2.GetPrevision()\n",
        "print (objClient2.currentConfusionMatriz)\n",
        "\n",
        "\n",
        "#objClient3.LoadTestData()\n",
        "objClient3.GetPrevision()\n",
        "print (objClient3.currentConfusionMatriz)\n",
        "\n",
        "#########################Registrando no Servidor Central#######################################\n",
        "\n",
        "objServe.RegisterClient(objClient1)\n",
        "objServe.RegisterClient(objClient2)\n",
        "objServe.RegisterClient(objClient3)\n",
        "\n",
        "#########################Consolidando os modelos#######################################\n",
        "\n",
        "objServe.ConsolidateModels()\n",
        "objServe.FeedBackConsolidatedModel()\n",
        "\n",
        "#########################Testando o novo modelo#######################################\n",
        "#########################Atualizando, conforme o caso#######################################\n",
        "\n",
        "objClient1.RefreshModel()\n",
        "print (objClient1.currentConfusionMatriz)\n",
        "objClient2.RefreshModel()\n",
        "print (objClient2.currentConfusionMatriz)\n",
        "objClient3.RefreshModel()\n",
        "print (objClient2.currentConfusionMatriz)\n",
        "\n",
        "#########################Novas matrizes, após atualização ou não dos modelos#######################################\n",
        "\n",
        "objClient1.GetPrevision()\n",
        "print (objClient1.currentConfusionMatriz)\n",
        "objClient2.GetPrevision()\n",
        "print (objClient2.currentConfusionMatriz)\n",
        "objClient3.GetPrevision()\n",
        "print (objClient3.currentConfusionMatriz)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "Ynh0ZgIyKk4t",
        "outputId": "0cc8e6dc-08a5-4f86-e5c3-92c8fa7eaf1b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-975f1cc6361f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#objClient1.LoadTestData()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mobjClient1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetPrevision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobjClient1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentConfusionMatriz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-80c044be6537>\u001b[0m in \u001b[0;36mGetPrevision\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m     '''\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mGetPrevision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#evalueta indica que é uma avaliação do modelo recebido como parametro, no caso do servidor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m       \u001b[0mtest_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadTestData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m       \u001b[0mprevisoes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0;31m#previsoes = parNeuralModel.predict(self.test_vectors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-80c044be6537>\u001b[0m in \u001b[0;36mLoadTestData\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0mbase_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m       \u001b[0mbase_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_teste\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_congestion_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_teste\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_teste\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Client' object has no attribute 'base_teste'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FKDnx_BcTkT-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}